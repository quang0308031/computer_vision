{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgnKrIClpqU7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datas = np.load('/content/drive/MyDrive/final_data/dataset.npy')\n",
        "labels = np.load('/content/drive/MyDrive/final_data/labels.npy')\n",
        "val_datas = np.load('/content/drive/MyDrive/final_data/val_dataset.npy')\n",
        "val_labels = np.load('/content/drive/MyDrive/final_data/val_labels.npy')"
      ],
      "metadata": {
        "id": "GcF9nAf7pylH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "plEgxIPJrdaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(scale=1./255.),\n",
        "    tf.keras.layers.Reshape((-1, 100*100)),\n",
        "    tf.keras.layers.LSTM(256),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "IT4eG6BAqSvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "\n",
        "labels_onehot = encoder.fit_transform(labels.reshape(-1, 1)).toarray()\n",
        "val_labels_onehot = encoder.fit_transform(val_labels.reshape(-1, 1)).toarray()"
      ],
      "metadata": {
        "id": "HZUkVEsBrB_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0z8MtQ7qrO9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/LS.keras', monitor='val_accuracy', verbose=2, save_best_only=True)"
      ],
      "metadata": {
        "id": "Xz89FxtdrRhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=datas, y=labels_onehot, batch_size=64, epochs=1000, validation_data=[val_datas, val_labels_onehot], callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yq2LjizprVeA",
        "outputId": "470131f7-d65b-4e61-881c-f4444a94a2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "46/47 [============================>.] - ETA: 0s - loss: 1.3289 - accuracy: 0.5622\n",
            "Epoch 1: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 4s 78ms/step - loss: 1.3267 - accuracy: 0.5626 - val_loss: 2.2758 - val_accuracy: 0.4023\n",
            "Epoch 2/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3254 - accuracy: 0.5660\n",
            "Epoch 2: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 1.3250 - accuracy: 0.5650 - val_loss: 2.1172 - val_accuracy: 0.3998\n",
            "Epoch 3/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3356 - accuracy: 0.5510\n",
            "Epoch 3: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.3418 - accuracy: 0.5487 - val_loss: 2.2319 - val_accuracy: 0.4119\n",
            "Epoch 4/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.3251 - accuracy: 0.5555\n",
            "Epoch 4: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 1.3251 - accuracy: 0.5555 - val_loss: 2.3913 - val_accuracy: 0.3655\n",
            "Epoch 5/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3886 - accuracy: 0.5347\n",
            "Epoch 5: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 1.3941 - accuracy: 0.5332 - val_loss: 2.1418 - val_accuracy: 0.4028\n",
            "Epoch 6/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3394 - accuracy: 0.5538\n",
            "Epoch 6: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.3423 - accuracy: 0.5528 - val_loss: 2.2131 - val_accuracy: 0.4054\n",
            "Epoch 7/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3427 - accuracy: 0.5528\n",
            "Epoch 7: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.3415 - accuracy: 0.5542 - val_loss: 2.4284 - val_accuracy: 0.3847\n",
            "Epoch 8/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.2972 - accuracy: 0.5684\n",
            "Epoch 8: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.2922 - accuracy: 0.5708 - val_loss: 2.1700 - val_accuracy: 0.4185\n",
            "Epoch 9/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3986 - accuracy: 0.5333\n",
            "Epoch 9: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.3947 - accuracy: 0.5355 - val_loss: 2.3807 - val_accuracy: 0.3624\n",
            "Epoch 10/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3433 - accuracy: 0.5583\n",
            "Epoch 10: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.3435 - accuracy: 0.5575 - val_loss: 2.2936 - val_accuracy: 0.3811\n",
            "Epoch 11/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.3537 - accuracy: 0.5427\n",
            "Epoch 11: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 1.3537 - accuracy: 0.5427 - val_loss: 2.2396 - val_accuracy: 0.4160\n",
            "Epoch 12/1000\n",
            "46/47 [============================>.] - ETA: 0s - loss: 1.3067 - accuracy: 0.5771\n",
            "Epoch 12: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 1.3079 - accuracy: 0.5768 - val_loss: 2.7932 - val_accuracy: 0.3150\n",
            "Epoch 13/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.5243 - accuracy: 0.5027\n",
            "Epoch 13: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.5243 - accuracy: 0.5027 - val_loss: 2.3726 - val_accuracy: 0.4028\n",
            "Epoch 14/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4388 - accuracy: 0.5378\n",
            "Epoch 14: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.4413 - accuracy: 0.5366 - val_loss: 2.3224 - val_accuracy: 0.3958\n",
            "Epoch 15/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4477 - accuracy: 0.5299\n",
            "Epoch 15: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.4514 - accuracy: 0.5284 - val_loss: 2.3034 - val_accuracy: 0.3392\n",
            "Epoch 16/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4532 - accuracy: 0.5306\n",
            "Epoch 16: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.4540 - accuracy: 0.5301 - val_loss: 2.3036 - val_accuracy: 0.3872\n",
            "Epoch 17/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.4510 - accuracy: 0.5349\n",
            "Epoch 17: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 1.4510 - accuracy: 0.5349 - val_loss: 2.5127 - val_accuracy: 0.3110\n",
            "Epoch 18/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4798 - accuracy: 0.5177\n",
            "Epoch 18: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 1.4759 - accuracy: 0.5193 - val_loss: 2.3862 - val_accuracy: 0.4018\n",
            "Epoch 19/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4513 - accuracy: 0.5264\n",
            "Epoch 19: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.4514 - accuracy: 0.5257 - val_loss: 2.4384 - val_accuracy: 0.3574\n",
            "Epoch 20/1000\n",
            "46/47 [============================>.] - ETA: 0s - loss: 1.3574 - accuracy: 0.5591\n",
            "Epoch 20: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 1.3598 - accuracy: 0.5586 - val_loss: 2.3866 - val_accuracy: 0.3705\n",
            "Epoch 21/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4260 - accuracy: 0.5257\n",
            "Epoch 21: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.4238 - accuracy: 0.5278 - val_loss: 2.3622 - val_accuracy: 0.3847\n",
            "Epoch 22/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.3788 - accuracy: 0.5603\n",
            "Epoch 22: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.3788 - accuracy: 0.5603 - val_loss: 2.3197 - val_accuracy: 0.3781\n",
            "Epoch 23/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4027 - accuracy: 0.5424\n",
            "Epoch 23: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 1.4078 - accuracy: 0.5413 - val_loss: 2.3149 - val_accuracy: 0.3675\n",
            "Epoch 24/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.3631 - accuracy: 0.5633\n",
            "Epoch 24: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.3631 - accuracy: 0.5633 - val_loss: 2.4143 - val_accuracy: 0.3872\n",
            "Epoch 25/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3581 - accuracy: 0.5580\n",
            "Epoch 25: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 1.3612 - accuracy: 0.5572 - val_loss: 2.4096 - val_accuracy: 0.3115\n",
            "Epoch 26/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4392 - accuracy: 0.5253\n",
            "Epoch 26: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.4331 - accuracy: 0.5267 - val_loss: 2.2769 - val_accuracy: 0.3847\n",
            "Epoch 27/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.3115 - accuracy: 0.5694\n",
            "Epoch 27: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.3115 - accuracy: 0.5694 - val_loss: 2.4267 - val_accuracy: 0.3392\n",
            "Epoch 28/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.5891 - accuracy: 0.4969\n",
            "Epoch 28: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.6047 - accuracy: 0.4942 - val_loss: 2.3063 - val_accuracy: 0.3518\n",
            "Epoch 29/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.7658 - accuracy: 0.4309\n",
            "Epoch 29: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.7619 - accuracy: 0.4323 - val_loss: 2.2314 - val_accuracy: 0.3266\n",
            "Epoch 30/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.6728 - accuracy: 0.4792\n",
            "Epoch 30: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 1.6654 - accuracy: 0.4817 - val_loss: 2.3520 - val_accuracy: 0.3019\n",
            "Epoch 31/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.6228 - accuracy: 0.4913\n",
            "Epoch 31: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 1.6247 - accuracy: 0.4895 - val_loss: 2.3833 - val_accuracy: 0.2761\n",
            "Epoch 32/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.5030 - accuracy: 0.5194\n",
            "Epoch 32: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.5022 - accuracy: 0.5196 - val_loss: 2.3349 - val_accuracy: 0.3392\n",
            "Epoch 33/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4426 - accuracy: 0.5267\n",
            "Epoch 33: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.4545 - accuracy: 0.5244 - val_loss: 2.6287 - val_accuracy: 0.1943\n",
            "Epoch 34/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.5656 - accuracy: 0.4844\n",
            "Epoch 34: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.5570 - accuracy: 0.4882 - val_loss: 2.2422 - val_accuracy: 0.3705\n",
            "Epoch 35/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3611 - accuracy: 0.5597\n",
            "Epoch 35: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.3593 - accuracy: 0.5609 - val_loss: 2.2827 - val_accuracy: 0.3423\n",
            "Epoch 36/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.3713 - accuracy: 0.5592\n",
            "Epoch 36: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 1.3713 - accuracy: 0.5592 - val_loss: 2.4330 - val_accuracy: 0.3443\n",
            "Epoch 37/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3850 - accuracy: 0.5469\n",
            "Epoch 37: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 1.3875 - accuracy: 0.5471 - val_loss: 2.4472 - val_accuracy: 0.3523\n",
            "Epoch 38/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4088 - accuracy: 0.5441\n",
            "Epoch 38: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.4104 - accuracy: 0.5457 - val_loss: 2.3158 - val_accuracy: 0.3801\n",
            "Epoch 39/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3585 - accuracy: 0.5601\n",
            "Epoch 39: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.3618 - accuracy: 0.5589 - val_loss: 2.5811 - val_accuracy: 0.2807\n",
            "Epoch 40/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3892 - accuracy: 0.5528\n",
            "Epoch 40: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.3862 - accuracy: 0.5538 - val_loss: 2.5094 - val_accuracy: 0.3417\n",
            "Epoch 41/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4349 - accuracy: 0.5295\n",
            "Epoch 41: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.4326 - accuracy: 0.5284 - val_loss: 2.3544 - val_accuracy: 0.3907\n",
            "Epoch 42/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3112 - accuracy: 0.5753\n",
            "Epoch 42: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.3128 - accuracy: 0.5741 - val_loss: 2.4658 - val_accuracy: 0.3266\n",
            "Epoch 43/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.3309 - accuracy: 0.5613\n",
            "Epoch 43: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 1.3309 - accuracy: 0.5613 - val_loss: 2.4971 - val_accuracy: 0.3256\n",
            "Epoch 44/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.2573 - accuracy: 0.6003\n",
            "Epoch 44: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.2561 - accuracy: 0.5992 - val_loss: 2.4837 - val_accuracy: 0.3619\n",
            "Epoch 45/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3101 - accuracy: 0.5726\n",
            "Epoch 45: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.3185 - accuracy: 0.5708 - val_loss: 2.8437 - val_accuracy: 0.3347\n",
            "Epoch 46/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4220 - accuracy: 0.5333\n",
            "Epoch 46: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.4198 - accuracy: 0.5328 - val_loss: 2.3787 - val_accuracy: 0.3619\n",
            "Epoch 47/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3650 - accuracy: 0.5514\n",
            "Epoch 47: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 1.3683 - accuracy: 0.5491 - val_loss: 2.5030 - val_accuracy: 0.3529\n",
            "Epoch 48/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3446 - accuracy: 0.5667\n",
            "Epoch 48: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 1.3381 - accuracy: 0.5694 - val_loss: 2.6334 - val_accuracy: 0.3968\n",
            "Epoch 49/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.3504 - accuracy: 0.5687\n",
            "Epoch 49: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 1.3504 - accuracy: 0.5687 - val_loss: 2.5969 - val_accuracy: 0.3236\n",
            "Epoch 50/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4965 - accuracy: 0.5201\n",
            "Epoch 50: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 1.4902 - accuracy: 0.5220 - val_loss: 2.4576 - val_accuracy: 0.3715\n",
            "Epoch 51/1000\n",
            "46/47 [============================>.] - ETA: 0s - loss: 1.3427 - accuracy: 0.5645\n",
            "Epoch 51: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 1.3410 - accuracy: 0.5647 - val_loss: 2.4806 - val_accuracy: 0.3281\n",
            "Epoch 52/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.2208 - accuracy: 0.5903\n",
            "Epoch 52: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.2132 - accuracy: 0.5934 - val_loss: 2.3939 - val_accuracy: 0.4038\n",
            "Epoch 53/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.2367 - accuracy: 0.5906\n",
            "Epoch 53: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.2377 - accuracy: 0.5894 - val_loss: 2.5769 - val_accuracy: 0.3963\n",
            "Epoch 54/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.2320 - accuracy: 0.5872\n",
            "Epoch 54: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.2295 - accuracy: 0.5860 - val_loss: 2.7102 - val_accuracy: 0.2908\n",
            "Epoch 55/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.1499 - accuracy: 0.6293\n",
            "Epoch 55: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 1.1499 - accuracy: 0.6293 - val_loss: 2.6274 - val_accuracy: 0.3210\n",
            "Epoch 56/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3086 - accuracy: 0.5653\n",
            "Epoch 56: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 43ms/step - loss: 1.3104 - accuracy: 0.5664 - val_loss: 2.6751 - val_accuracy: 0.3751\n",
            "Epoch 57/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.3455 - accuracy: 0.5562\n",
            "Epoch 57: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.3432 - accuracy: 0.5569 - val_loss: 2.4096 - val_accuracy: 0.3665\n",
            "Epoch 58/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.1860 - accuracy: 0.6038\n",
            "Epoch 58: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.1807 - accuracy: 0.6060 - val_loss: 2.5626 - val_accuracy: 0.3887\n",
            "Epoch 59/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.1586 - accuracy: 0.6024\n",
            "Epoch 59: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.1649 - accuracy: 0.6026 - val_loss: 2.5527 - val_accuracy: 0.4064\n",
            "Epoch 60/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.1800 - accuracy: 0.6052\n",
            "Epoch 60: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.1757 - accuracy: 0.6070 - val_loss: 2.5734 - val_accuracy: 0.3291\n",
            "Epoch 61/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.0800 - accuracy: 0.6483\n",
            "Epoch 61: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 1.0829 - accuracy: 0.6483 - val_loss: 2.6938 - val_accuracy: 0.3135\n",
            "Epoch 62/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.2921 - accuracy: 0.5755\n",
            "Epoch 62: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 1.2921 - accuracy: 0.5755 - val_loss: 2.6841 - val_accuracy: 0.3301\n",
            "Epoch 63/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.2024 - accuracy: 0.6010\n",
            "Epoch 63: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.2032 - accuracy: 0.6002 - val_loss: 2.7603 - val_accuracy: 0.3256\n",
            "Epoch 64/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.1796 - accuracy: 0.6087\n",
            "Epoch 64: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.1868 - accuracy: 0.6066 - val_loss: 3.1097 - val_accuracy: 0.3276\n",
            "Epoch 65/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.2368 - accuracy: 0.5934\n",
            "Epoch 65: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.2328 - accuracy: 0.5944 - val_loss: 2.6999 - val_accuracy: 0.3352\n",
            "Epoch 66/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.1418 - accuracy: 0.6222\n",
            "Epoch 66: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.1426 - accuracy: 0.6219 - val_loss: 2.8114 - val_accuracy: 0.3039\n",
            "Epoch 67/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.2840 - accuracy: 0.5694\n",
            "Epoch 67: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.2921 - accuracy: 0.5674 - val_loss: 2.6339 - val_accuracy: 0.3069\n",
            "Epoch 68/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.5815 - accuracy: 0.4834\n",
            "Epoch 68: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 1.5815 - accuracy: 0.4834 - val_loss: 2.4440 - val_accuracy: 0.3372\n",
            "Epoch 69/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.5795 - accuracy: 0.4726\n",
            "Epoch 69: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 1.5759 - accuracy: 0.4753 - val_loss: 2.5471 - val_accuracy: 0.3534\n",
            "Epoch 70/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4927 - accuracy: 0.5097\n",
            "Epoch 70: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.4856 - accuracy: 0.5132 - val_loss: 2.5258 - val_accuracy: 0.3251\n",
            "Epoch 71/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.5078 - accuracy: 0.5031\n",
            "Epoch 71: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.5071 - accuracy: 0.5044 - val_loss: 2.4984 - val_accuracy: 0.3493\n",
            "Epoch 72/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4533 - accuracy: 0.5128\n",
            "Epoch 72: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.4579 - accuracy: 0.5118 - val_loss: 2.6025 - val_accuracy: 0.3296\n",
            "Epoch 73/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4537 - accuracy: 0.5181\n",
            "Epoch 73: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.4513 - accuracy: 0.5193 - val_loss: 2.7778 - val_accuracy: 0.3508\n",
            "Epoch 74/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.7195 - accuracy: 0.4533\n",
            "Epoch 74: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 1.7195 - accuracy: 0.4533 - val_loss: 2.4507 - val_accuracy: 0.3236\n",
            "Epoch 75/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4984 - accuracy: 0.5080\n",
            "Epoch 75: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 43ms/step - loss: 1.4986 - accuracy: 0.5088 - val_loss: 2.6897 - val_accuracy: 0.3099\n",
            "Epoch 76/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4807 - accuracy: 0.5090\n",
            "Epoch 76: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.4748 - accuracy: 0.5102 - val_loss: 2.5905 - val_accuracy: 0.3210\n",
            "Epoch 77/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4427 - accuracy: 0.5253\n",
            "Epoch 77: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.4397 - accuracy: 0.5267 - val_loss: 2.8127 - val_accuracy: 0.3120\n",
            "Epoch 78/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4642 - accuracy: 0.5201\n",
            "Epoch 78: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.4630 - accuracy: 0.5210 - val_loss: 2.5117 - val_accuracy: 0.3185\n",
            "Epoch 79/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4389 - accuracy: 0.5344\n",
            "Epoch 79: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.4348 - accuracy: 0.5342 - val_loss: 2.7031 - val_accuracy: 0.3241\n",
            "Epoch 80/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.4700 - accuracy: 0.5128\n",
            "Epoch 80: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.4705 - accuracy: 0.5122 - val_loss: 2.7248 - val_accuracy: 0.2847\n",
            "Epoch 81/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.4806 - accuracy: 0.5156\n",
            "Epoch 81: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 1.4806 - accuracy: 0.5156 - val_loss: 2.5360 - val_accuracy: 0.3332\n",
            "Epoch 82/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9202 - accuracy: 0.3528\n",
            "Epoch 82: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 1.9222 - accuracy: 0.3507 - val_loss: 2.4408 - val_accuracy: 0.2948\n",
            "Epoch 83/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9481 - accuracy: 0.3278\n",
            "Epoch 83: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.9556 - accuracy: 0.3267 - val_loss: 2.7610 - val_accuracy: 0.2802\n",
            "Epoch 84/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8948 - accuracy: 0.3420\n",
            "Epoch 84: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.8963 - accuracy: 0.3402 - val_loss: 2.5496 - val_accuracy: 0.2832\n",
            "Epoch 85/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9283 - accuracy: 0.3444\n",
            "Epoch 85: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.9258 - accuracy: 0.3453 - val_loss: 2.6652 - val_accuracy: 0.2872\n",
            "Epoch 86/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9851 - accuracy: 0.3278\n",
            "Epoch 86: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9826 - accuracy: 0.3277 - val_loss: 2.5779 - val_accuracy: 0.2978\n",
            "Epoch 87/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.8909 - accuracy: 0.3500\n",
            "Epoch 87: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 1.8909 - accuracy: 0.3500 - val_loss: 2.5254 - val_accuracy: 0.2953\n",
            "Epoch 88/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8788 - accuracy: 0.3472\n",
            "Epoch 88: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.8838 - accuracy: 0.3470 - val_loss: 2.5692 - val_accuracy: 0.2832\n",
            "Epoch 89/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9597 - accuracy: 0.3264\n",
            "Epoch 89: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.9576 - accuracy: 0.3284 - val_loss: 2.7635 - val_accuracy: 0.2923\n",
            "Epoch 90/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9164 - accuracy: 0.3424\n",
            "Epoch 90: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.9135 - accuracy: 0.3412 - val_loss: 2.6813 - val_accuracy: 0.2529\n",
            "Epoch 91/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9888 - accuracy: 0.3264\n",
            "Epoch 91: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9880 - accuracy: 0.3284 - val_loss: 2.7319 - val_accuracy: 0.3014\n",
            "Epoch 92/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8815 - accuracy: 0.3503\n",
            "Epoch 92: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.8875 - accuracy: 0.3490 - val_loss: 2.6990 - val_accuracy: 0.3044\n",
            "Epoch 93/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8824 - accuracy: 0.3517\n",
            "Epoch 93: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.8820 - accuracy: 0.3541 - val_loss: 2.6199 - val_accuracy: 0.2998\n",
            "Epoch 94/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.8659 - accuracy: 0.3541\n",
            "Epoch 94: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 1.8659 - accuracy: 0.3541 - val_loss: 2.4758 - val_accuracy: 0.2973\n",
            "Epoch 95/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9381 - accuracy: 0.3392\n",
            "Epoch 95: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.9316 - accuracy: 0.3416 - val_loss: 2.5666 - val_accuracy: 0.2958\n",
            "Epoch 96/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.9282 - accuracy: 0.3382\n",
            "Epoch 96: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.9282 - accuracy: 0.3382 - val_loss: 2.5862 - val_accuracy: 0.3231\n",
            "Epoch 97/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9564 - accuracy: 0.3306\n",
            "Epoch 97: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9583 - accuracy: 0.3311 - val_loss: 3.3753 - val_accuracy: 0.2539\n",
            "Epoch 98/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9119 - accuracy: 0.3302\n",
            "Epoch 98: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9096 - accuracy: 0.3307 - val_loss: 2.6297 - val_accuracy: 0.2847\n",
            "Epoch 99/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8810 - accuracy: 0.3462\n",
            "Epoch 99: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.8883 - accuracy: 0.3466 - val_loss: 2.8192 - val_accuracy: 0.3069\n",
            "Epoch 100/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.8897 - accuracy: 0.3443\n",
            "Epoch 100: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 1.8897 - accuracy: 0.3443 - val_loss: 2.7076 - val_accuracy: 0.2877\n",
            "Epoch 101/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9169 - accuracy: 0.3403\n",
            "Epoch 101: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 1.9183 - accuracy: 0.3412 - val_loss: 2.7389 - val_accuracy: 0.2367\n",
            "Epoch 102/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8875 - accuracy: 0.3483\n",
            "Epoch 102: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.8814 - accuracy: 0.3497 - val_loss: 2.6971 - val_accuracy: 0.2887\n",
            "Epoch 103/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8609 - accuracy: 0.3684\n",
            "Epoch 103: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.8595 - accuracy: 0.3676 - val_loss: 2.6445 - val_accuracy: 0.2938\n",
            "Epoch 104/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8472 - accuracy: 0.3701\n",
            "Epoch 104: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.8478 - accuracy: 0.3710 - val_loss: 2.9448 - val_accuracy: 0.2277\n",
            "Epoch 105/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8707 - accuracy: 0.3479\n",
            "Epoch 105: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.8768 - accuracy: 0.3480 - val_loss: 2.6863 - val_accuracy: 0.2948\n",
            "Epoch 106/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.9103 - accuracy: 0.3514\n",
            "Epoch 106: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 1.9103 - accuracy: 0.3514 - val_loss: 2.7635 - val_accuracy: 0.3039\n",
            "Epoch 107/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.8732 - accuracy: 0.3534\n",
            "Epoch 107: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 1.8732 - accuracy: 0.3534 - val_loss: 3.2129 - val_accuracy: 0.2736\n",
            "Epoch 108/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8852 - accuracy: 0.3566\n",
            "Epoch 108: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.8807 - accuracy: 0.3582 - val_loss: 3.0738 - val_accuracy: 0.2988\n",
            "Epoch 109/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8314 - accuracy: 0.3587\n",
            "Epoch 109: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.8316 - accuracy: 0.3592 - val_loss: 2.8164 - val_accuracy: 0.3009\n",
            "Epoch 110/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8695 - accuracy: 0.3646\n",
            "Epoch 110: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.8663 - accuracy: 0.3659 - val_loss: 2.8283 - val_accuracy: 0.2852\n",
            "Epoch 111/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8257 - accuracy: 0.3760\n",
            "Epoch 111: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.8291 - accuracy: 0.3741 - val_loss: 2.7894 - val_accuracy: 0.2822\n",
            "Epoch 112/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9502 - accuracy: 0.3434\n",
            "Epoch 112: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.9524 - accuracy: 0.3416 - val_loss: 2.7923 - val_accuracy: 0.2938\n",
            "Epoch 113/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.8778 - accuracy: 0.3568\n",
            "Epoch 113: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 1.8778 - accuracy: 0.3568 - val_loss: 3.1407 - val_accuracy: 0.3064\n",
            "Epoch 114/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9375 - accuracy: 0.3521\n",
            "Epoch 114: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 1.9383 - accuracy: 0.3524 - val_loss: 2.7613 - val_accuracy: 0.2292\n",
            "Epoch 115/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8245 - accuracy: 0.3812\n",
            "Epoch 115: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.8193 - accuracy: 0.3825 - val_loss: 2.6566 - val_accuracy: 0.2983\n",
            "Epoch 116/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9080 - accuracy: 0.3587\n",
            "Epoch 116: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.9085 - accuracy: 0.3595 - val_loss: 2.6292 - val_accuracy: 0.2887\n",
            "Epoch 117/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.7955 - accuracy: 0.3722\n",
            "Epoch 117: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.7898 - accuracy: 0.3751 - val_loss: 2.7291 - val_accuracy: 0.3074\n",
            "Epoch 118/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8472 - accuracy: 0.3729\n",
            "Epoch 118: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.8462 - accuracy: 0.3737 - val_loss: 2.9726 - val_accuracy: 0.2857\n",
            "Epoch 119/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.8451 - accuracy: 0.3703\n",
            "Epoch 119: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 1.8451 - accuracy: 0.3703 - val_loss: 2.9285 - val_accuracy: 0.2807\n",
            "Epoch 120/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.8876 - accuracy: 0.3676\n",
            "Epoch 120: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 50ms/step - loss: 1.8876 - accuracy: 0.3676 - val_loss: 2.6901 - val_accuracy: 0.2423\n",
            "Epoch 121/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.2599 - accuracy: 0.2698\n",
            "Epoch 121: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 2.2599 - accuracy: 0.2698 - val_loss: 2.4491 - val_accuracy: 0.2746\n",
            "Epoch 122/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1578 - accuracy: 0.3035\n",
            "Epoch 122: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.1591 - accuracy: 0.3043 - val_loss: 2.7099 - val_accuracy: 0.2776\n",
            "Epoch 123/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1369 - accuracy: 0.3024\n",
            "Epoch 123: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.1354 - accuracy: 0.3043 - val_loss: 2.5968 - val_accuracy: 0.2615\n",
            "Epoch 124/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1232 - accuracy: 0.3146\n",
            "Epoch 124: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.1204 - accuracy: 0.3162 - val_loss: 2.4955 - val_accuracy: 0.2771\n",
            "Epoch 125/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1226 - accuracy: 0.3160\n",
            "Epoch 125: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.1254 - accuracy: 0.3145 - val_loss: 2.7158 - val_accuracy: 0.2680\n",
            "Epoch 126/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1438 - accuracy: 0.3031\n",
            "Epoch 126: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.1474 - accuracy: 0.3037 - val_loss: 2.4650 - val_accuracy: 0.2731\n",
            "Epoch 127/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1519 - accuracy: 0.3059\n",
            "Epoch 127: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 2.1502 - accuracy: 0.3067 - val_loss: 2.7030 - val_accuracy: 0.2665\n",
            "Epoch 128/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1713 - accuracy: 0.3003\n",
            "Epoch 128: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 2.1713 - accuracy: 0.3016 - val_loss: 2.5816 - val_accuracy: 0.2655\n",
            "Epoch 129/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1647 - accuracy: 0.3090\n",
            "Epoch 129: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.1576 - accuracy: 0.3125 - val_loss: 2.5400 - val_accuracy: 0.2726\n",
            "Epoch 130/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1498 - accuracy: 0.3156\n",
            "Epoch 130: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.1491 - accuracy: 0.3155 - val_loss: 3.3475 - val_accuracy: 0.2499\n",
            "Epoch 131/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1727 - accuracy: 0.2948\n",
            "Epoch 131: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.1711 - accuracy: 0.2955 - val_loss: 2.5465 - val_accuracy: 0.2660\n",
            "Epoch 132/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0962 - accuracy: 0.3243\n",
            "Epoch 132: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.0968 - accuracy: 0.3257 - val_loss: 2.4817 - val_accuracy: 0.2726\n",
            "Epoch 133/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.2372 - accuracy: 0.2830\n",
            "Epoch 133: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 43ms/step - loss: 2.2372 - accuracy: 0.2830 - val_loss: 2.6153 - val_accuracy: 0.2484\n",
            "Epoch 134/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.1087 - accuracy: 0.3101\n",
            "Epoch 134: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.1087 - accuracy: 0.3101 - val_loss: 2.4957 - val_accuracy: 0.2696\n",
            "Epoch 135/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0854 - accuracy: 0.3243\n",
            "Epoch 135: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.0875 - accuracy: 0.3246 - val_loss: 2.4997 - val_accuracy: 0.2620\n",
            "Epoch 136/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1155 - accuracy: 0.3153\n",
            "Epoch 136: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.1192 - accuracy: 0.3131 - val_loss: 2.6827 - val_accuracy: 0.2615\n",
            "Epoch 137/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0822 - accuracy: 0.3201\n",
            "Epoch 137: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.0780 - accuracy: 0.3196 - val_loss: 2.7735 - val_accuracy: 0.2595\n",
            "Epoch 138/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0762 - accuracy: 0.3278\n",
            "Epoch 138: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.0711 - accuracy: 0.3301 - val_loss: 2.6021 - val_accuracy: 0.2721\n",
            "Epoch 139/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0362 - accuracy: 0.3486\n",
            "Epoch 139: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.0432 - accuracy: 0.3450 - val_loss: 2.7760 - val_accuracy: 0.2428\n",
            "Epoch 140/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1871 - accuracy: 0.2934\n",
            "Epoch 140: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 2.1885 - accuracy: 0.2935 - val_loss: 2.4765 - val_accuracy: 0.2741\n",
            "Epoch 141/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1331 - accuracy: 0.2997\n",
            "Epoch 141: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 2.1319 - accuracy: 0.3009 - val_loss: 2.8535 - val_accuracy: 0.2756\n",
            "Epoch 142/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0504 - accuracy: 0.3365\n",
            "Epoch 142: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.0456 - accuracy: 0.3382 - val_loss: 2.7876 - val_accuracy: 0.2509\n",
            "Epoch 143/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.0778 - accuracy: 0.3267\n",
            "Epoch 143: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.0778 - accuracy: 0.3267 - val_loss: 2.5454 - val_accuracy: 0.2660\n",
            "Epoch 144/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.2149 - accuracy: 0.2951\n",
            "Epoch 144: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.2182 - accuracy: 0.2928 - val_loss: 2.4855 - val_accuracy: 0.2751\n",
            "Epoch 145/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1877 - accuracy: 0.2865\n",
            "Epoch 145: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.1809 - accuracy: 0.2884 - val_loss: 2.6428 - val_accuracy: 0.2574\n",
            "Epoch 146/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.0359 - accuracy: 0.3375\n",
            "Epoch 146: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 2.0359 - accuracy: 0.3375 - val_loss: 2.8577 - val_accuracy: 0.2448\n",
            "Epoch 147/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.0582 - accuracy: 0.3348\n",
            "Epoch 147: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.0582 - accuracy: 0.3348 - val_loss: 2.8099 - val_accuracy: 0.2549\n",
            "Epoch 148/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0239 - accuracy: 0.3483\n",
            "Epoch 148: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.0238 - accuracy: 0.3463 - val_loss: 3.2879 - val_accuracy: 0.2504\n",
            "Epoch 149/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0318 - accuracy: 0.3378\n",
            "Epoch 149: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.0299 - accuracy: 0.3382 - val_loss: 2.6346 - val_accuracy: 0.2489\n",
            "Epoch 150/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0375 - accuracy: 0.3243\n",
            "Epoch 150: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.0368 - accuracy: 0.3240 - val_loss: 3.2174 - val_accuracy: 0.2726\n",
            "Epoch 151/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0557 - accuracy: 0.3288\n",
            "Epoch 151: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.0576 - accuracy: 0.3297 - val_loss: 2.7585 - val_accuracy: 0.2539\n",
            "Epoch 152/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.0752 - accuracy: 0.3287\n",
            "Epoch 152: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.0752 - accuracy: 0.3287 - val_loss: 2.6787 - val_accuracy: 0.2610\n",
            "Epoch 153/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.0574 - accuracy: 0.3355\n",
            "Epoch 153: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 2.0574 - accuracy: 0.3355 - val_loss: 2.8311 - val_accuracy: 0.2559\n",
            "Epoch 154/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0576 - accuracy: 0.3264\n",
            "Epoch 154: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 2.0569 - accuracy: 0.3263 - val_loss: 2.6996 - val_accuracy: 0.2519\n",
            "Epoch 155/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.0417 - accuracy: 0.3483\n",
            "Epoch 155: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.0417 - accuracy: 0.3483 - val_loss: 2.8026 - val_accuracy: 0.2489\n",
            "Epoch 156/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0550 - accuracy: 0.3281\n",
            "Epoch 156: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.0540 - accuracy: 0.3301 - val_loss: 2.9477 - val_accuracy: 0.2605\n",
            "Epoch 157/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0137 - accuracy: 0.3472\n",
            "Epoch 157: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.0173 - accuracy: 0.3453 - val_loss: 3.0720 - val_accuracy: 0.2580\n",
            "Epoch 158/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0677 - accuracy: 0.3201\n",
            "Epoch 158: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.0619 - accuracy: 0.3240 - val_loss: 3.2122 - val_accuracy: 0.2595\n",
            "Epoch 159/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.0198 - accuracy: 0.3439\n",
            "Epoch 159: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 2.0198 - accuracy: 0.3439 - val_loss: 2.8761 - val_accuracy: 0.2448\n",
            "Epoch 160/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0235 - accuracy: 0.3444\n",
            "Epoch 160: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 2.0229 - accuracy: 0.3439 - val_loss: 2.9038 - val_accuracy: 0.2514\n",
            "Epoch 161/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0403 - accuracy: 0.3389\n",
            "Epoch 161: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.0357 - accuracy: 0.3402 - val_loss: 3.1609 - val_accuracy: 0.2448\n",
            "Epoch 162/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9994 - accuracy: 0.3594\n",
            "Epoch 162: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9978 - accuracy: 0.3585 - val_loss: 3.0514 - val_accuracy: 0.2529\n",
            "Epoch 163/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9939 - accuracy: 0.3611\n",
            "Epoch 163: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9944 - accuracy: 0.3612 - val_loss: 3.1509 - val_accuracy: 0.2544\n",
            "Epoch 164/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.1537 - accuracy: 0.3035\n",
            "Epoch 164: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.1533 - accuracy: 0.3030 - val_loss: 3.1995 - val_accuracy: 0.2494\n",
            "Epoch 165/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9726 - accuracy: 0.3611\n",
            "Epoch 165: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.9669 - accuracy: 0.3636 - val_loss: 2.9278 - val_accuracy: 0.2398\n",
            "Epoch 166/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.9726 - accuracy: 0.3555\n",
            "Epoch 166: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 1.9726 - accuracy: 0.3555 - val_loss: 3.2058 - val_accuracy: 0.2504\n",
            "Epoch 167/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9845 - accuracy: 0.3569\n",
            "Epoch 167: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.9795 - accuracy: 0.3588 - val_loss: 3.2231 - val_accuracy: 0.2458\n",
            "Epoch 168/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9548 - accuracy: 0.3594\n",
            "Epoch 168: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9597 - accuracy: 0.3605 - val_loss: 3.2463 - val_accuracy: 0.2585\n",
            "Epoch 169/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0017 - accuracy: 0.3580\n",
            "Epoch 169: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.0050 - accuracy: 0.3551 - val_loss: 2.8621 - val_accuracy: 0.2438\n",
            "Epoch 170/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9537 - accuracy: 0.3747\n",
            "Epoch 170: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.9525 - accuracy: 0.3751 - val_loss: 3.0642 - val_accuracy: 0.2393\n",
            "Epoch 171/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0008 - accuracy: 0.3465\n",
            "Epoch 171: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9996 - accuracy: 0.3466 - val_loss: 3.4935 - val_accuracy: 0.2423\n",
            "Epoch 172/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.9477 - accuracy: 0.3720\n",
            "Epoch 172: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 1.9477 - accuracy: 0.3720 - val_loss: 3.4196 - val_accuracy: 0.2539\n",
            "Epoch 173/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9779 - accuracy: 0.3483\n",
            "Epoch 173: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9736 - accuracy: 0.3487 - val_loss: 2.8810 - val_accuracy: 0.2423\n",
            "Epoch 174/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.0180 - accuracy: 0.3368\n",
            "Epoch 174: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.0164 - accuracy: 0.3389 - val_loss: 2.9809 - val_accuracy: 0.2418\n",
            "Epoch 175/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9487 - accuracy: 0.3764\n",
            "Epoch 175: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9486 - accuracy: 0.3785 - val_loss: 3.3489 - val_accuracy: 0.2504\n",
            "Epoch 176/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9293 - accuracy: 0.3715\n",
            "Epoch 176: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9265 - accuracy: 0.3724 - val_loss: 3.0817 - val_accuracy: 0.2433\n",
            "Epoch 177/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.9433 - accuracy: 0.3687\n",
            "Epoch 177: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9433 - accuracy: 0.3687 - val_loss: 3.1508 - val_accuracy: 0.2337\n",
            "Epoch 178/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8907 - accuracy: 0.3878\n",
            "Epoch 178: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 1.8906 - accuracy: 0.3863 - val_loss: 3.2785 - val_accuracy: 0.2590\n",
            "Epoch 179/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.9302 - accuracy: 0.3903\n",
            "Epoch 179: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.9302 - accuracy: 0.3903 - val_loss: 3.3217 - val_accuracy: 0.2620\n",
            "Epoch 180/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9949 - accuracy: 0.3545\n",
            "Epoch 180: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9901 - accuracy: 0.3551 - val_loss: 3.0886 - val_accuracy: 0.2378\n",
            "Epoch 181/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9482 - accuracy: 0.3684\n",
            "Epoch 181: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9505 - accuracy: 0.3687 - val_loss: 3.1525 - val_accuracy: 0.2418\n",
            "Epoch 182/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9211 - accuracy: 0.3747\n",
            "Epoch 182: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9273 - accuracy: 0.3734 - val_loss: 3.1249 - val_accuracy: 0.2357\n",
            "Epoch 183/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9239 - accuracy: 0.3771\n",
            "Epoch 183: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9247 - accuracy: 0.3761 - val_loss: 3.3986 - val_accuracy: 0.2519\n",
            "Epoch 184/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9012 - accuracy: 0.3861\n",
            "Epoch 184: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.8933 - accuracy: 0.3890 - val_loss: 3.9302 - val_accuracy: 0.2317\n",
            "Epoch 185/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.9146 - accuracy: 0.3879\n",
            "Epoch 185: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 1.9146 - accuracy: 0.3879 - val_loss: 3.2650 - val_accuracy: 0.2393\n",
            "Epoch 186/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9266 - accuracy: 0.3809\n",
            "Epoch 186: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 1.9218 - accuracy: 0.3829 - val_loss: 3.4719 - val_accuracy: 0.2489\n",
            "Epoch 187/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9084 - accuracy: 0.3774\n",
            "Epoch 187: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.9113 - accuracy: 0.3751 - val_loss: 3.6740 - val_accuracy: 0.2484\n",
            "Epoch 188/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.8958 - accuracy: 0.3819\n",
            "Epoch 188: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.8981 - accuracy: 0.3832 - val_loss: 3.5710 - val_accuracy: 0.2544\n",
            "Epoch 189/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 1.9091 - accuracy: 0.3830\n",
            "Epoch 189: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.9018 - accuracy: 0.3852 - val_loss: 2.9797 - val_accuracy: 0.2706\n",
            "Epoch 190/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5828 - accuracy: 0.2361\n",
            "Epoch 190: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.5843 - accuracy: 0.2366 - val_loss: 2.5082 - val_accuracy: 0.2559\n",
            "Epoch 191/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5073 - accuracy: 0.2407\n",
            "Epoch 191: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 43ms/step - loss: 2.5073 - accuracy: 0.2407 - val_loss: 2.4951 - val_accuracy: 0.2539\n",
            "Epoch 192/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5271 - accuracy: 0.2390\n",
            "Epoch 192: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 2.5271 - accuracy: 0.2390 - val_loss: 2.4911 - val_accuracy: 0.2559\n",
            "Epoch 193/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5099 - accuracy: 0.2441\n",
            "Epoch 193: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 50ms/step - loss: 2.5099 - accuracy: 0.2441 - val_loss: 2.5614 - val_accuracy: 0.2484\n",
            "Epoch 194/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5135 - accuracy: 0.2431\n",
            "Epoch 194: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5142 - accuracy: 0.2431 - val_loss: 2.4938 - val_accuracy: 0.2539\n",
            "Epoch 195/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5207 - accuracy: 0.2378\n",
            "Epoch 195: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5176 - accuracy: 0.2383 - val_loss: 2.4950 - val_accuracy: 0.2539\n",
            "Epoch 196/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4985 - accuracy: 0.2465\n",
            "Epoch 196: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.4978 - accuracy: 0.2461 - val_loss: 2.5043 - val_accuracy: 0.2519\n",
            "Epoch 197/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5053 - accuracy: 0.2434\n",
            "Epoch 197: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5078 - accuracy: 0.2424 - val_loss: 2.5030 - val_accuracy: 0.2559\n",
            "Epoch 198/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5051 - accuracy: 0.2438\n",
            "Epoch 198: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 2.5083 - accuracy: 0.2431 - val_loss: 2.5633 - val_accuracy: 0.2509\n",
            "Epoch 199/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5070 - accuracy: 0.2431\n",
            "Epoch 199: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 2.5070 - accuracy: 0.2431 - val_loss: 2.5052 - val_accuracy: 0.2519\n",
            "Epoch 200/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5012 - accuracy: 0.2441\n",
            "Epoch 200: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 2.5035 - accuracy: 0.2427 - val_loss: 2.5487 - val_accuracy: 0.2544\n",
            "Epoch 201/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5126 - accuracy: 0.2427\n",
            "Epoch 201: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5118 - accuracy: 0.2407 - val_loss: 2.5919 - val_accuracy: 0.2509\n",
            "Epoch 202/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4924 - accuracy: 0.2438\n",
            "Epoch 202: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.4939 - accuracy: 0.2434 - val_loss: 2.5165 - val_accuracy: 0.2509\n",
            "Epoch 203/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5108 - accuracy: 0.2424\n",
            "Epoch 203: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5094 - accuracy: 0.2417 - val_loss: 2.5107 - val_accuracy: 0.2509\n",
            "Epoch 204/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5137 - accuracy: 0.2424\n",
            "Epoch 204: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5180 - accuracy: 0.2420 - val_loss: 2.4919 - val_accuracy: 0.2559\n",
            "Epoch 205/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4950 - accuracy: 0.2471\n",
            "Epoch 205: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 2.4950 - accuracy: 0.2471 - val_loss: 2.5297 - val_accuracy: 0.2499\n",
            "Epoch 206/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4933 - accuracy: 0.2478\n",
            "Epoch 206: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 2.4933 - accuracy: 0.2478 - val_loss: 2.4906 - val_accuracy: 0.2559\n",
            "Epoch 207/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5086 - accuracy: 0.2420\n",
            "Epoch 207: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5108 - accuracy: 0.2420 - val_loss: 2.5009 - val_accuracy: 0.2539\n",
            "Epoch 208/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5098 - accuracy: 0.2438\n",
            "Epoch 208: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5096 - accuracy: 0.2431 - val_loss: 2.4979 - val_accuracy: 0.2539\n",
            "Epoch 209/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4857 - accuracy: 0.2486\n",
            "Epoch 209: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.4852 - accuracy: 0.2478 - val_loss: 2.5609 - val_accuracy: 0.2509\n",
            "Epoch 210/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5178 - accuracy: 0.2396\n",
            "Epoch 210: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.5162 - accuracy: 0.2390 - val_loss: 2.5405 - val_accuracy: 0.2509\n",
            "Epoch 211/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5101 - accuracy: 0.2420\n",
            "Epoch 211: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 2.5101 - accuracy: 0.2420 - val_loss: 2.5180 - val_accuracy: 0.2519\n",
            "Epoch 212/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4999 - accuracy: 0.2461\n",
            "Epoch 212: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.4999 - accuracy: 0.2461 - val_loss: 2.4939 - val_accuracy: 0.2539\n",
            "Epoch 213/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5151 - accuracy: 0.2406\n",
            "Epoch 213: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 2.5119 - accuracy: 0.2414 - val_loss: 2.5295 - val_accuracy: 0.2519\n",
            "Epoch 214/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5033 - accuracy: 0.2448\n",
            "Epoch 214: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5058 - accuracy: 0.2431 - val_loss: 2.5340 - val_accuracy: 0.2509\n",
            "Epoch 215/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5022 - accuracy: 0.2434\n",
            "Epoch 215: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4997 - accuracy: 0.2441 - val_loss: 2.5563 - val_accuracy: 0.2514\n",
            "Epoch 216/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5159 - accuracy: 0.2424\n",
            "Epoch 216: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5138 - accuracy: 0.2420 - val_loss: 2.5535 - val_accuracy: 0.2514\n",
            "Epoch 217/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4788 - accuracy: 0.2486\n",
            "Epoch 217: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.4801 - accuracy: 0.2481 - val_loss: 2.5337 - val_accuracy: 0.2509\n",
            "Epoch 218/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5013 - accuracy: 0.2441\n",
            "Epoch 218: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 2.5013 - accuracy: 0.2441 - val_loss: 2.5140 - val_accuracy: 0.2509\n",
            "Epoch 219/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5075 - accuracy: 0.2444\n",
            "Epoch 219: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5075 - accuracy: 0.2444 - val_loss: 2.5064 - val_accuracy: 0.2539\n",
            "Epoch 220/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5066 - accuracy: 0.2431\n",
            "Epoch 220: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5057 - accuracy: 0.2431 - val_loss: 2.5252 - val_accuracy: 0.2504\n",
            "Epoch 221/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5250 - accuracy: 0.2393\n",
            "Epoch 221: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5250 - accuracy: 0.2393 - val_loss: 2.5137 - val_accuracy: 0.2559\n",
            "Epoch 222/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5002 - accuracy: 0.2455\n",
            "Epoch 222: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5027 - accuracy: 0.2441 - val_loss: 2.5204 - val_accuracy: 0.2509\n",
            "Epoch 223/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5057 - accuracy: 0.2427\n",
            "Epoch 223: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5041 - accuracy: 0.2420 - val_loss: 2.5487 - val_accuracy: 0.2509\n",
            "Epoch 224/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5014 - accuracy: 0.2431\n",
            "Epoch 224: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5014 - accuracy: 0.2431 - val_loss: 2.5015 - val_accuracy: 0.2539\n",
            "Epoch 225/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5218 - accuracy: 0.2383\n",
            "Epoch 225: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 2.5218 - accuracy: 0.2383 - val_loss: 2.5162 - val_accuracy: 0.2519\n",
            "Epoch 226/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5016 - accuracy: 0.2451\n",
            "Epoch 226: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4963 - accuracy: 0.2471 - val_loss: 2.5060 - val_accuracy: 0.2539\n",
            "Epoch 227/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5094 - accuracy: 0.2413\n",
            "Epoch 227: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5121 - accuracy: 0.2407 - val_loss: 2.5255 - val_accuracy: 0.2499\n",
            "Epoch 228/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5120 - accuracy: 0.2438\n",
            "Epoch 228: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.5140 - accuracy: 0.2424 - val_loss: 2.5274 - val_accuracy: 0.2519\n",
            "Epoch 229/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5047 - accuracy: 0.2406\n",
            "Epoch 229: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5043 - accuracy: 0.2420 - val_loss: 2.5072 - val_accuracy: 0.2519\n",
            "Epoch 230/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5228 - accuracy: 0.2389\n",
            "Epoch 230: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5283 - accuracy: 0.2376 - val_loss: 2.5085 - val_accuracy: 0.2559\n",
            "Epoch 231/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5082 - accuracy: 0.2434\n",
            "Epoch 231: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 2.5082 - accuracy: 0.2434 - val_loss: 2.5452 - val_accuracy: 0.2514\n",
            "Epoch 232/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5004 - accuracy: 0.2438\n",
            "Epoch 232: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 43ms/step - loss: 2.4996 - accuracy: 0.2427 - val_loss: 2.5797 - val_accuracy: 0.2514\n",
            "Epoch 233/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4997 - accuracy: 0.2444\n",
            "Epoch 233: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5036 - accuracy: 0.2434 - val_loss: 2.5187 - val_accuracy: 0.2504\n",
            "Epoch 234/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5177 - accuracy: 0.2392\n",
            "Epoch 234: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.5139 - accuracy: 0.2414 - val_loss: 2.5473 - val_accuracy: 0.2514\n",
            "Epoch 235/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4971 - accuracy: 0.2471\n",
            "Epoch 235: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 2.4971 - accuracy: 0.2471 - val_loss: 2.5324 - val_accuracy: 0.2519\n",
            "Epoch 236/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5105 - accuracy: 0.2399\n",
            "Epoch 236: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5088 - accuracy: 0.2414 - val_loss: 2.5202 - val_accuracy: 0.2539\n",
            "Epoch 237/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5032 - accuracy: 0.2434\n",
            "Epoch 237: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 2.5032 - accuracy: 0.2434 - val_loss: 2.5280 - val_accuracy: 0.2499\n",
            "Epoch 238/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4802 - accuracy: 0.2531\n",
            "Epoch 238: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.4817 - accuracy: 0.2525 - val_loss: 2.5392 - val_accuracy: 0.2448\n",
            "Epoch 239/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4965 - accuracy: 0.2444\n",
            "Epoch 239: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4987 - accuracy: 0.2434 - val_loss: 2.5345 - val_accuracy: 0.2494\n",
            "Epoch 240/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4996 - accuracy: 0.2451\n",
            "Epoch 240: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5004 - accuracy: 0.2434 - val_loss: 2.5126 - val_accuracy: 0.2519\n",
            "Epoch 241/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4982 - accuracy: 0.2427\n",
            "Epoch 241: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.4988 - accuracy: 0.2417 - val_loss: 2.5483 - val_accuracy: 0.2529\n",
            "Epoch 242/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5066 - accuracy: 0.2438\n",
            "Epoch 242: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.5066 - accuracy: 0.2431 - val_loss: 2.5126 - val_accuracy: 0.2544\n",
            "Epoch 243/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4904 - accuracy: 0.2458\n",
            "Epoch 243: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4913 - accuracy: 0.2448 - val_loss: 2.5252 - val_accuracy: 0.2509\n",
            "Epoch 244/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5037 - accuracy: 0.2448\n",
            "Epoch 244: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 2.5059 - accuracy: 0.2437 - val_loss: 2.5380 - val_accuracy: 0.2519\n",
            "Epoch 245/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5188 - accuracy: 0.2434\n",
            "Epoch 245: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 43ms/step - loss: 2.5204 - accuracy: 0.2420 - val_loss: 2.5315 - val_accuracy: 0.2544\n",
            "Epoch 246/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5160 - accuracy: 0.2393\n",
            "Epoch 246: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5160 - accuracy: 0.2393 - val_loss: 2.5171 - val_accuracy: 0.2539\n",
            "Epoch 247/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4865 - accuracy: 0.2462\n",
            "Epoch 247: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 2.4887 - accuracy: 0.2444 - val_loss: 2.7200 - val_accuracy: 0.2494\n",
            "Epoch 248/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5320 - accuracy: 0.2372\n",
            "Epoch 248: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.5297 - accuracy: 0.2387 - val_loss: 2.5585 - val_accuracy: 0.2524\n",
            "Epoch 249/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5074 - accuracy: 0.2417\n",
            "Epoch 249: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5078 - accuracy: 0.2424 - val_loss: 2.5311 - val_accuracy: 0.2559\n",
            "Epoch 250/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5047 - accuracy: 0.2437\n",
            "Epoch 250: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5047 - accuracy: 0.2437 - val_loss: 2.5278 - val_accuracy: 0.2428\n",
            "Epoch 251/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5014 - accuracy: 0.2431\n",
            "Epoch 251: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 2.5014 - accuracy: 0.2431 - val_loss: 2.5134 - val_accuracy: 0.2514\n",
            "Epoch 252/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5129 - accuracy: 0.2410\n",
            "Epoch 252: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5134 - accuracy: 0.2414 - val_loss: 2.5232 - val_accuracy: 0.2519\n",
            "Epoch 253/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4942 - accuracy: 0.2448\n",
            "Epoch 253: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.4968 - accuracy: 0.2431 - val_loss: 2.5822 - val_accuracy: 0.2569\n",
            "Epoch 254/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5039 - accuracy: 0.2410\n",
            "Epoch 254: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5048 - accuracy: 0.2414 - val_loss: 2.5076 - val_accuracy: 0.2539\n",
            "Epoch 255/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4954 - accuracy: 0.2455\n",
            "Epoch 255: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 2.4938 - accuracy: 0.2451 - val_loss: 2.5263 - val_accuracy: 0.2519\n",
            "Epoch 256/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4911 - accuracy: 0.2441\n",
            "Epoch 256: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.4893 - accuracy: 0.2451 - val_loss: 2.5559 - val_accuracy: 0.2524\n",
            "Epoch 257/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4997 - accuracy: 0.2462\n",
            "Epoch 257: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 2.5037 - accuracy: 0.2451 - val_loss: 2.5087 - val_accuracy: 0.2519\n",
            "Epoch 258/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5201 - accuracy: 0.2385\n",
            "Epoch 258: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5116 - accuracy: 0.2410 - val_loss: 2.5927 - val_accuracy: 0.2529\n",
            "Epoch 259/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4825 - accuracy: 0.2469\n",
            "Epoch 259: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.4828 - accuracy: 0.2464 - val_loss: 2.5627 - val_accuracy: 0.2524\n",
            "Epoch 260/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5224 - accuracy: 0.2382\n",
            "Epoch 260: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5232 - accuracy: 0.2383 - val_loss: 2.5131 - val_accuracy: 0.2519\n",
            "Epoch 261/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4994 - accuracy: 0.2431\n",
            "Epoch 261: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4979 - accuracy: 0.2431 - val_loss: 2.5142 - val_accuracy: 0.2544\n",
            "Epoch 262/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5059 - accuracy: 0.2406\n",
            "Epoch 262: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5005 - accuracy: 0.2420 - val_loss: 2.5903 - val_accuracy: 0.2494\n",
            "Epoch 263/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4987 - accuracy: 0.2420\n",
            "Epoch 263: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 2.4987 - accuracy: 0.2420 - val_loss: 2.5100 - val_accuracy: 0.2544\n",
            "Epoch 264/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5083 - accuracy: 0.2424\n",
            "Epoch 264: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 2.5083 - accuracy: 0.2424 - val_loss: 2.5046 - val_accuracy: 0.2544\n",
            "Epoch 265/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5207 - accuracy: 0.2383\n",
            "Epoch 265: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 2.5207 - accuracy: 0.2383 - val_loss: 2.8520 - val_accuracy: 0.2438\n",
            "Epoch 266/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5069 - accuracy: 0.2431\n",
            "Epoch 266: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 2.5130 - accuracy: 0.2410 - val_loss: 2.5456 - val_accuracy: 0.2448\n",
            "Epoch 267/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5076 - accuracy: 0.2403\n",
            "Epoch 267: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5046 - accuracy: 0.2417 - val_loss: 2.5481 - val_accuracy: 0.2514\n",
            "Epoch 268/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4900 - accuracy: 0.2458\n",
            "Epoch 268: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4902 - accuracy: 0.2454 - val_loss: 2.5020 - val_accuracy: 0.2539\n",
            "Epoch 269/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4945 - accuracy: 0.2414\n",
            "Epoch 269: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 2.4945 - accuracy: 0.2414 - val_loss: 2.5005 - val_accuracy: 0.2539\n",
            "Epoch 270/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5097 - accuracy: 0.2410\n",
            "Epoch 270: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 50ms/step - loss: 2.5097 - accuracy: 0.2410 - val_loss: 2.5169 - val_accuracy: 0.2519\n",
            "Epoch 271/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4996 - accuracy: 0.2407\n",
            "Epoch 271: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 2.4996 - accuracy: 0.2407 - val_loss: 2.5108 - val_accuracy: 0.2499\n",
            "Epoch 272/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5109 - accuracy: 0.2417\n",
            "Epoch 272: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5072 - accuracy: 0.2417 - val_loss: 2.5121 - val_accuracy: 0.2519\n",
            "Epoch 273/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5061 - accuracy: 0.2396\n",
            "Epoch 273: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5068 - accuracy: 0.2414 - val_loss: 2.5668 - val_accuracy: 0.2544\n",
            "Epoch 274/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5021 - accuracy: 0.2455\n",
            "Epoch 274: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5075 - accuracy: 0.2434 - val_loss: 2.5220 - val_accuracy: 0.2519\n",
            "Epoch 275/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5160 - accuracy: 0.2399\n",
            "Epoch 275: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5142 - accuracy: 0.2400 - val_loss: 2.5072 - val_accuracy: 0.2519\n",
            "Epoch 276/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4974 - accuracy: 0.2424\n",
            "Epoch 276: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 2.4974 - accuracy: 0.2424 - val_loss: 2.5544 - val_accuracy: 0.2514\n",
            "Epoch 277/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5138 - accuracy: 0.2403\n",
            "Epoch 277: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 2.5149 - accuracy: 0.2387 - val_loss: 2.5493 - val_accuracy: 0.2524\n",
            "Epoch 278/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4908 - accuracy: 0.2448\n",
            "Epoch 278: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4908 - accuracy: 0.2448 - val_loss: 2.5271 - val_accuracy: 0.2499\n",
            "Epoch 279/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5049 - accuracy: 0.2393\n",
            "Epoch 279: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5049 - accuracy: 0.2393 - val_loss: 2.5138 - val_accuracy: 0.2539\n",
            "Epoch 280/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4761 - accuracy: 0.2486\n",
            "Epoch 280: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4758 - accuracy: 0.2475 - val_loss: 2.5910 - val_accuracy: 0.2534\n",
            "Epoch 281/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5057 - accuracy: 0.2448\n",
            "Epoch 281: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 2.5084 - accuracy: 0.2420 - val_loss: 2.5452 - val_accuracy: 0.2514\n",
            "Epoch 282/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5026 - accuracy: 0.2420\n",
            "Epoch 282: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 2.5026 - accuracy: 0.2420 - val_loss: 2.5429 - val_accuracy: 0.2509\n",
            "Epoch 283/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5002 - accuracy: 0.2424\n",
            "Epoch 283: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 2.5002 - accuracy: 0.2424 - val_loss: 2.6050 - val_accuracy: 0.2509\n",
            "Epoch 284/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4870 - accuracy: 0.2427\n",
            "Epoch 284: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.4844 - accuracy: 0.2448 - val_loss: 2.6033 - val_accuracy: 0.2549\n",
            "Epoch 285/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4889 - accuracy: 0.2417\n",
            "Epoch 285: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.4884 - accuracy: 0.2434 - val_loss: 2.5307 - val_accuracy: 0.2408\n",
            "Epoch 286/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5059 - accuracy: 0.2403\n",
            "Epoch 286: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5043 - accuracy: 0.2417 - val_loss: 2.6064 - val_accuracy: 0.2519\n",
            "Epoch 287/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4996 - accuracy: 0.2427\n",
            "Epoch 287: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.4988 - accuracy: 0.2427 - val_loss: 2.5248 - val_accuracy: 0.2549\n",
            "Epoch 288/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4970 - accuracy: 0.2420\n",
            "Epoch 288: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 2.4970 - accuracy: 0.2420 - val_loss: 2.5670 - val_accuracy: 0.2453\n",
            "Epoch 289/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4897 - accuracy: 0.2478\n",
            "Epoch 289: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 2.4897 - accuracy: 0.2478 - val_loss: 2.5247 - val_accuracy: 0.2499\n",
            "Epoch 290/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5053 - accuracy: 0.2417\n",
            "Epoch 290: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5056 - accuracy: 0.2410 - val_loss: 2.6099 - val_accuracy: 0.2524\n",
            "Epoch 291/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5107 - accuracy: 0.2396\n",
            "Epoch 291: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5067 - accuracy: 0.2414 - val_loss: 2.5295 - val_accuracy: 0.2504\n",
            "Epoch 292/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5130 - accuracy: 0.2427\n",
            "Epoch 292: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 2.5134 - accuracy: 0.2414 - val_loss: 2.5696 - val_accuracy: 0.2524\n",
            "Epoch 293/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4943 - accuracy: 0.2468\n",
            "Epoch 293: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 2.4943 - accuracy: 0.2468 - val_loss: 2.5267 - val_accuracy: 0.2509\n",
            "Epoch 294/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4896 - accuracy: 0.2444\n",
            "Epoch 294: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4903 - accuracy: 0.2448 - val_loss: 2.5668 - val_accuracy: 0.2504\n",
            "Epoch 295/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4935 - accuracy: 0.2468\n",
            "Epoch 295: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 2.4935 - accuracy: 0.2468 - val_loss: 2.5138 - val_accuracy: 0.2549\n",
            "Epoch 296/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.4824 - accuracy: 0.2485\n",
            "Epoch 296: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 2.4824 - accuracy: 0.2485 - val_loss: 2.6558 - val_accuracy: 0.1545\n",
            "Epoch 297/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.5053 - accuracy: 0.2441\n",
            "Epoch 297: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.5052 - accuracy: 0.2434 - val_loss: 2.5162 - val_accuracy: 0.2524\n",
            "Epoch 298/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4984 - accuracy: 0.2410\n",
            "Epoch 298: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4988 - accuracy: 0.2417 - val_loss: 2.5282 - val_accuracy: 0.2529\n",
            "Epoch 299/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4755 - accuracy: 0.2483\n",
            "Epoch 299: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4788 - accuracy: 0.2464 - val_loss: 2.5254 - val_accuracy: 0.2529\n",
            "Epoch 300/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 2.4958 - accuracy: 0.2431\n",
            "Epoch 300: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 2.4910 - accuracy: 0.2441 - val_loss: 2.5331 - val_accuracy: 0.2559\n",
            "Epoch 301/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 2.5079 - accuracy: 0.2417\n",
            "Epoch 301: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 2.5079 - accuracy: 0.2417 - val_loss: 2.5164 - val_accuracy: 0.2529\n",
            "Epoch 302/1000\n",
            "46/47 [============================>.] - ETA: 0s - loss: 2.5029 - accuracy: 0.2408\n",
            "Epoch 302: val_accuracy did not improve from 0.48258\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 2.5035 - accuracy: 0.2404 - val_loss: 2.6037 - val_accuracy: 0.2509\n",
            "Epoch 303/1000\n",
            "13/47 [=======>......................] - ETA: 1s - loss: 2.4741 - accuracy: 0.2440"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-28336ddc2751>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_datas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels_onehot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    632\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m   \"\"\"\n\u001b[1;32m   1065\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/LS.keras')"
      ],
      "metadata": {
        "id": "Qt6fr6jFsanx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(val_datas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vMEMSt-woKI",
        "outputId": "dd706485-f47d-4a8b-e628-f9110d455b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 1s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(y_pred, axis=1 )"
      ],
      "metadata": {
        "id": "CIBy1j6dwsOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "8cCZVsD4wx-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(np.argmax(val_labels_onehot, axis=1), y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxUhM2llw2n0",
        "outputId": "68c71e7f-80db-4511-84ca-086016023870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.88      0.71       310\n",
            "           1       0.51      0.50      0.50       218\n",
            "           2       0.29      0.03      0.06        62\n",
            "           3       0.60      0.64      0.62        64\n",
            "           4       0.41      0.48      0.44        62\n",
            "           5       0.78      0.35      0.48        72\n",
            "           6       0.12      0.09      0.10        56\n",
            "           7       0.60      0.67      0.63       195\n",
            "           8       0.13      0.48      0.21       102\n",
            "           9       0.23      0.13      0.17        91\n",
            "          10       0.39      0.48      0.43       112\n",
            "          11       0.00      0.00      0.00        66\n",
            "          12       0.00      0.00      0.00        50\n",
            "          13       0.00      0.00      0.00        56\n",
            "          14       0.00      0.00      0.00        46\n",
            "          15       0.33      0.07      0.11        59\n",
            "          16       0.23      0.04      0.07        70\n",
            "          17       0.00      0.00      0.00        47\n",
            "          18       0.89      0.94      0.91        17\n",
            "          19       0.75      0.90      0.82       226\n",
            "\n",
            "    accuracy                           0.48      1981\n",
            "   macro avg       0.34      0.33      0.31      1981\n",
            "weighted avg       0.43      0.48      0.43      1981\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import auc, average_precision_score"
      ],
      "metadata": {
        "id": "X62ArRk6xBZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(average_precision_score(np.argmax(val_labels_onehot, axis=1), y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "UrRhJg7ixSF0",
        "outputId": "42019c86-712c-436a-d83f-77b5259fe043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "multiclass format is not supported",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-64513c10b796>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0m_binary_uninterpolated_average_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     )\n\u001b[0;32m--> 234\u001b[0;31m     return _average_binary_score(\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0maverage_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DONUxqKKxqM6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}